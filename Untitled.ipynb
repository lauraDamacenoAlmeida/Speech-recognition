{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d98bf1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b76152ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3dd482c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gTTS\n",
      "  Downloading gTTS-2.5.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Users/lauradamaceno/opt/anaconda3/lib/python3.9/site-packages (from gTTS) (2.27.1)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in /Users/lauradamaceno/opt/anaconda3/lib/python3.9/site-packages (from gTTS) (8.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/lauradamaceno/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27->gTTS) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lauradamaceno/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27->gTTS) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/lauradamaceno/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27->gTTS) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lauradamaceno/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27->gTTS) (3.3)\n",
      "Downloading gTTS-2.5.1-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: gTTS\n",
      "Successfully installed gTTS-2.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cafa9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting playsound\n",
      "  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: playsound\n",
      "  Building wheel for playsound (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7035 sha256=b844c77701ff9dc9fab33218d3e3d9089239d4f89b7431c78bf0577f5bc6f77e\n",
      "  Stored in directory: /Users/lauradamaceno/Library/Caches/pip/wheels/ba/39/54/c8f7ff9a88a644d3c58b4dec802d90b79a2e0fb2a6b884bf82\n",
      "Successfully built playsound\n",
      "Installing collected packages: playsound\n",
      "Successfully installed playsound-1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02df786d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3dd6517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/lauradamaceno/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     /Users/lauradamaceno/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lauradamaceno/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# from TwitterSearch import *\n",
    "\n",
    "import codecs\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('rslp')\n",
    "nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import unidecode\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.stem import RSLPStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59e91e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "playsound is relying on a python 2 subprocess. Please use `pip3 install PyObjC` if you want playsound to run more efficiently.\n"
     ]
    }
   ],
   "source": [
    "from gtts import gTTS\n",
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4880348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauradamaceno/opt/anaconda3/lib/python3.9/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from emot.emo_unicode import UNICODE_EMO, EMOTICONS\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38e2baba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "#Funcao responsavel por ouvir e reconhecer a fala\n",
    "def ouvir_microfone():\n",
    " #Habilita o microfone para ouvir o usuario\n",
    "    microfone = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "  #Chama a funcao de reducao de ruido disponivel na speech_recognition\n",
    "        microfone.adjust_for_ambient_noise(source)\n",
    "  #Avisa ao usuario que esta pronto para ouvir\n",
    "        print(\"Diga alguma coisa: \")\n",
    "  #Armazena a informacao de audio na variavel\n",
    "        audio = microfone.listen(source)\n",
    "    try:\n",
    "      #Passa o audio para o reconhecedor de padroes do speech_recognition\n",
    "      frase = microfone.recognize_google(audio,language='pt-BR')\n",
    "      #Após alguns segundos, retorna a frase falada\n",
    "      print(\"Você disse: \" + frase)\n",
    "    #Caso nao tenha reconhecido o padrao de fala, exibe esta mensagem\n",
    "    except sr.UnkownValueError:\n",
    "        print(\"Não entendi\")\n",
    "    return frase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e69f63",
   "metadata": {},
   "source": [
    "### Repetir frase dita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b09cc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_audio(audio):\n",
    "    tts = gTTS(audio,lang='pt-br')\n",
    " #Salva o arquivo de audio\n",
    "    tts.save('audios/hello.mp3')\n",
    "    print(\"Estou aprendendo o que você disse...\")\n",
    " #Da play ao audio\n",
    "    #playsound('audios/hello.mp3')\n",
    "    song= AudioSegment.from_mp3('audios/hello.mp3')\n",
    "    play(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a67a9032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diga alguma coisa: \n",
      "Você disse: Ei Jarvis queria saber quais híbridos são os mais importantes de soja que eu posso aplicar aqui no meu campo\n"
     ]
    }
   ],
   "source": [
    "frase_dita = ouvir_microfone()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "43d38d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ei Jarvis queria saber quais híbridos são os mais importantes de soja que eu posso aplicar aqui no meu campo'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase_dita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "527d6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cria_audio(frase_dita)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d438fa",
   "metadata": {},
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a1c528f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_pontuacao = tokenize.WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c55fca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "pontuacao = list()\n",
    "for ponto in punctuation:\n",
    "    pontuacao.append(ponto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "60245851",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frase_processada = list()\n",
    "def tokenize_frase(frase):\n",
    "    stemmer = RSLPStemmer()\n",
    "    palavras_texto = frase.lower()\n",
    "    palavras_texto = token_pontuacao.tokenize(palavras_texto)\n",
    "    palavra = []\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    #Adicionando novas stopwords em português\n",
    "    stopwords.append('ja')\n",
    "    stopwords.append('viu')\n",
    "    stopwords.append('vai')\n",
    "    stopwords.append('ne')\n",
    "    stopwords.append('ai')\n",
    "    stopwords.append('ta')\n",
    "    stopwords.append('gente')\n",
    "    stopwords.append('aqui')\n",
    "    stopwords.append('tambem')\n",
    "    stopwords.append('vc')\n",
    "    stopwords.append('voce')\n",
    "    stopwords.append('entao')\n",
    "    stopwords.append('ate')\n",
    "    stopwords.append('agora')\n",
    "    stopwords.append('ser')\n",
    "    stopwords.append('sempre')\n",
    "    stopwords.append('ter')\n",
    "    stopwords.append('so')\n",
    "    stopwords.append('porque')\n",
    "    stopwords.append('sobre')\n",
    "    stopwords.append('ainda')\n",
    "    stopwords.append('la')\n",
    "    stopwords.append('tudo')\n",
    "    stopwords.append('ninguem')\n",
    "    stopwords.append('de')\n",
    "    stopwords.append('pra')\n",
    "    for i in palavras_texto:\n",
    "        if not i.isnumeric() and i.lower() not in stopwords and i not in pontuacao and len(i)> 2:\n",
    "            #palavra.append(stemmer.stem(i.lower()))\n",
    "\n",
    "            palavra.append(i.lower())\n",
    "    #     frase = nltk.word_tokenize(frase)\n",
    "    #frase_processada.append(' '.join(palavra))\n",
    "    frase_processada = ' '.join(palavra)\n",
    "    return frase_processada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "98b0d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removerAcentosECaracteresEspeciais(frase):\n",
    "    \n",
    "    frase_sem_acento = unidecode.unidecode(frase) #remove acentos\n",
    "    text = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', frase_sem_acento, flags=re.MULTILINE) #removendo url\n",
    "    print(text)\n",
    "    tex_sem_mention = re.sub(r'@\\w*','',text)\n",
    "    # Usa expressão regular para retornar a palavra apenas com letras e espaço\n",
    "    return re.sub('[^a-zA-Z \\\\\\ ]', ' ', tex_sem_mention)\n",
    "    #return frase_sem_acento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d3897ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data  = removerAcentosECaracteresEspeciais(data)\n",
    "#     print(data)\n",
    "    #data = convert_emojis_to_word(data)\n",
    "    return tokenize_frase(data)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "26619694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ei Jarvis queria saber quais hibridos sao os mais importantes de soja que eu posso aplicar aqui no meu campo\n"
     ]
    }
   ],
   "source": [
    "palavra_pre_processada = preprocess(frase_dita)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5f17c5",
   "metadata": {},
   "source": [
    "## Identificação de pontos relevantes da frase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b59ccc5",
   "metadata": {},
   "source": [
    "https://github.com/inoueMashuu/POS-tagger-portuguese-nltk/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ab46e96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('O', 'ART'),\n",
       " ('rato', 'N'),\n",
       " ('roeu', 'V'),\n",
       " ('a', 'ART'),\n",
       " ('roupa', 'N'),\n",
       " ('do', 'KS'),\n",
       " ('rei', 'N'),\n",
       " ('de', 'PREP'),\n",
       " ('Roma', 'NPROP')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from nltk import word_tokenize\n",
    "\n",
    "folder = 'POS-tagger-portuguese-nltk-master/trained_POS_taggers/'\n",
    "teste_tagger = joblib.load(folder+'POS_tagger_brill.pkl')\n",
    "phrase = 'O rato roeu a roupa do rei de Roma'\n",
    "teste_tagger.tag(word_tokenize(phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "34e2320b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jarvis', 'NPROP'),\n",
       " ('queria', 'V'),\n",
       " ('saber', 'V'),\n",
       " ('quais', 'PRO-KS'),\n",
       " ('hibridos', 'PCP'),\n",
       " ('sao', 'N'),\n",
       " ('importantes', 'ADJ'),\n",
       " ('soja', 'N'),\n",
       " ('posso', 'VAUX'),\n",
       " ('aplicar', 'V'),\n",
       " ('campo', 'N')]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste_tagger.tag(word_tokenize(palavra_pre_processada))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7449e805",
   "metadata": {},
   "source": [
    "Yet Another Keyword Extractor (Yake) library selects the most important keywords using the text statistical features method from the article. With the help of YAKE, you can control the extracted keyword word count and other features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "260c0ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1759225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad1b2eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_extractor = yake.KeywordExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8520992",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5ac5f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfKeywords = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bddb9592",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ngram_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2399bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "deduplication_threshold = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b9a69775",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, top=numOfKeywords, features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b8a4eda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = custom_kw_extractor.extract_keywords(palavra_pre_processada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5433ae9f",
   "metadata": {},
   "source": [
    "The duplication_threshold variable is limit the duplication of words in different keywords. You can set the deduplication_threshold value to 0.1 to avoid the repetition of words in keywords. If you set the deduplication_threshold value to 0.9, then repetition of words is allowed in keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "edd52c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('jarvis queria saber', 0.01655915082773619)\n",
      "('queria saber quais', 0.03339840940482845)\n",
      "('saber quais hibridos', 0.03339840940482845)\n"
     ]
    }
   ],
   "source": [
    "for kw in keywords:\n",
    "    print(kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb757a8",
   "metadata": {},
   "source": [
    "The lower the score, the more relevant the keyword is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a31ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
